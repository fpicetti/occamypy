{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple usage of Dask vectors and Dask operators\n",
    "\n",
    "@Author: Ettore Biondi - ebiondi@caltech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we describe the usage of the Dask-based classes. These objects are designed to take advantage of computational power of computer clusters composed of multiple nodes. To this end, we employ the existing classes in combination of Dask (https://dask.org/). We show the syntax with which a user can instantiate Dask-based objects from existing constructors using a local Dask cluster. The same syntax applies to the other supported Dask clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! DATAPATH not found. The folder /tmp will be used to write binary files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import occamypy as o\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import rcParams\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams.update({\n",
    "    'image.cmap'     : 'gray',\n",
    "    'image.aspect'   : 'auto',\n",
    "    'image.interpolation': None,\n",
    "    'axes.grid'      : False,\n",
    "    'figure.figsize' : (10, 6),\n",
    "    'savefig.dpi'    : 300,\n",
    "    'axes.labelsize' : 14,\n",
    "    'axes.titlesize' : 16,\n",
    "    'font.size'      : 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'text.usetex'    : True,\n",
    "    'font.family'    : 'serif',\n",
    "    'font.serif'     : 'Latin Modern Roman',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting a Dask cluster and client\n",
    "Let's start by starting a local Dask client and show how to get some information from such object. We are going to start 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DaskClient in module occamypy.dask.utils:\n",
      "\n",
      "class DaskClient(builtins.object)\n",
      " |  DaskClient(**kwargs)\n",
      " |  \n",
      " |  Class useful to construct a Dask Client to be used with Dask vectors and operators\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Constructor for obtaining a client to be used when Dask is necessary\n",
      " |      1) Cluster with shared file system and ssh capability:\n",
      " |      :param hostnames : - list; list of strings containing the host names or IP addresses of the machines that\n",
      " |      the user wants to use in their cluster/client (First hostname will be running the scheduler!) [None]\n",
      " |      :param scheduler_file_prefix : string; prefix to used to create dask scheduler-file.\n",
      " |      :param logging : - boolean; Logging scheduler and worker stdout to files within dask_logs folder [True]\n",
      " |      Must be a mounted path on all the machines. Necessary if hostnames are provided [$HOME/scheduler-]\n",
      " |      2) Local cluster:\n",
      " |      :param local_params : - dict; dictionary containing Local Cluster options (see help(LocalCluster) for help) [None]\n",
      " |      :param n_wrks: - int; number of workers to start [1]\n",
      " |      3) PBS cluster:\n",
      " |      :param pbs_params : - dict; dictionary containing PBS Cluster options (see help(PBSCluster) for help) [None]\n",
      " |      :param n_jobs : - int; number of jobs to be submitted to the cluster\n",
      " |      :param n_wrks: - int; number of workers per job [1]\n",
      " |      4) LSF cluster:\n",
      " |      :param lfs_params : - dict; dictionary containing LSF Cluster options (see help(LSFCluster) for help) [None]\n",
      " |      :param n_jobs : - int; number of jobs to be submitted to the cluster\n",
      " |      :param n_wrks: - int; number of workers per job [1]\n",
      " |      5) SLURM cluster:\n",
      " |      :param slurm_params : - dict; dictionary containing SLURM Cluster options (see help(SLURMCluster) for help) [None]\n",
      " |      :param n_jobs : - int; number of jobs to be submitted to the cluster\n",
      " |      :param n_wrks: - int; number of workers per job [1]\n",
      " |      6) Kubernetes cluster:\n",
      " |      :param kube_params : - dict; dictonary containing KubeCluster options\n",
      " |       (see help(KubeCluster) and help(make_pod_spec) for help) [None]\n",
      " |      :param n_wrks: - int; number of workers to scale the cluster\n",
      " |      Note that by default the Kubernetes pods are created using the Docker image \"ettore88/occamypy:devel\". To change\n",
      " |      the image to be use, provide the item image within the kube_params dictionary.\n",
      " |  \n",
      " |  getClient(self)\n",
      " |      Accessor for obtaining the client object\n",
      " |  \n",
      " |  getNworkers(self)\n",
      " |      Accessor for obtaining the number of workers\n",
      " |  \n",
      " |  getWorkerIds(self)\n",
      " |      Accessor for obtaining the worker IDs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(o.DaskClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_params = {\"processes\":True}\n",
    "client = o.DaskClient(local_params=client_params, n_wrks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers = 4\n",
      "Workers Ids = ['tcp://127.0.0.1:61062', 'tcp://127.0.0.1:61065', 'tcp://127.0.0.1:61068', 'tcp://127.0.0.1:61071']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of workers = %d\" % client.getNworkers())\n",
    "print(\"Workers Ids = %s\" % client.getWorkerIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask vectors\n",
    "Now that we have a Dask client, we can instantiate vectors using the Dask interface. The currently supported methods to create such objects are the following:\n",
    "1. Instantiate a vector template and spread it using the chunk parameter\n",
    "2. Instantiate multiple vectors and spreading them to the given workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "vec_temp = o.VectorNumpy((200, 300))\n",
    "chunks = (3, 4, 6, 2) # 3 vectors to worker 1; 4 vectors to worker 2; ...\n",
    "vecD = o.DaskVector(client, vector_template=vec_temp, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vecD inherits all the methods from the abstract vector class. Let's try some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300)]\n",
      "Dask vector norm = 547.419212126386\n",
      "Scaled Dask vector norm = 5474.192121263861\n",
      "Sum Dask vector norm = 10948.384242527722\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\" % vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\" % vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\" % vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1 + vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\" % vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dask vector contains a list of the future objects pointing to the vector chunks. Let's see how to see which worker has a given chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future object to first chunk: <Future: finished, type: occamypy.VectorNumpy, key: _call_clone-4dd6d028-f215-487b-a701-6fe2bcb4b593>\n",
      "Worker having given chunk: {'_call_clone-4dd6d028-f215-487b-a701-6fe2bcb4b593': ('tcp://127.0.0.1:61062',)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Future object to first chunk: %s\" % vecD.vecDask[0])\n",
    "print(\"Worker having given chunk: %s\" % client.getClient().who_has(vecD.vecDask[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a vector using a different Dask-vector constructor. Here, we instantiate all the chunks and then spread them onto the given workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = o.VectorNumpy((200, 300))\n",
    "vec2 = o.VectorNumpy((10, 30))\n",
    "vec3 = o.VectorNumpy((250, 1))\n",
    "# We use the parameter chunks to select which worker will have a given vector instance\n",
    "vecD = o.DaskVector(client, vectors=[vec1, vec2, vec3], chunks=(1, 1, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try similar tests as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(200, 300), (10, 30), (250, 1)]\n",
      "Dask vector norm = 142.35185759872147\n",
      "Scaled Dask vector norm = 1423.5185759872145\n",
      "Sum Dask vector norm = 2847.037151974429\n",
      "Future object to third chunk: <Future: finished, type: occamypy.VectorNumpy, key: VectorNumpy-4904d8dfefe3d63e434690b581731f64>\n",
      "Worker having given chunk: {'VectorNumpy-4904d8dfefe3d63e434690b581731f64': ('tcp://127.0.0.1:61071',)}\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\" % vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\" % vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\" % vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1 + vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\" % vecD1.norm())\n",
    "print(\"Future object to third chunk: %s\" % vecD.vecDask[2])\n",
    "print(\"Worker having given chunk: %s\" % client.getClient().who_has(vecD.vecDask[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask operators\n",
    "Now, let's try to instantiate Dask operators. These kind of objects are pretty useful when large-scale problems have to be solved. The main idea behind the interface is to pass a given operator constructor and the necessary parameters so that the object is directly instantiated within the Dask workers of a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simple scaling operator acting on each chunk of a Dask Vector\n",
    "vec = o.VectorNumpy((100, 25))\n",
    "chunks = (2, 3, 5, 10)\n",
    "sc = 10.0\n",
    "vecD = o.DaskVector(client, vector_template=vec, chunks=chunks)\n",
    "# Creating list of lists of the arguments for the operator's constructor\n",
    "scal_op_args = [(vec_i, sc) for vec_i in vecD.vecDask]\n",
    "\n",
    "# Instantiating Dask operator\n",
    "scaleOpD = o.DaskOperator(client, o.Scaling, scal_op_args, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the Dask vector class, a Dask operator object inherits all the methods from the corresponding abstract class. Let's try some of those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.08325624465942383 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.07850790023803711 seconds\n",
      "Dot products add=False: domain=1.083178e+03 range=1.083178e+03 \n",
      "Absolute error: 0.000000e+00\n",
      "Relative error: 0.000000e+00 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.0854029655456543 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.08702898025512695 seconds\n",
      "Dot products add=True: domain=2.166357e+03 range=2.166357e+03 \n",
      "Absolute error: 4.547474e-13\n",
      "Relative error: 2.099134e-16 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Maximum eigenvalue = 10.000000000000005\n"
     ]
    }
   ],
   "source": [
    "# Dot-product test\n",
    "scaleOpD.dotTest(True)\n",
    "# Power method\n",
    "max_eig = scaleOpD.powerMethod()\n",
    "print(\"\\nMaximum eigenvalue = %s\" % max_eig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to apply this Dask operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the input = 129.12552942808634\n",
      "Norm of the output = 1291.2552942808636\n"
     ]
    }
   ],
   "source": [
    "vecD.rand()\n",
    "vecD1 = scaleOpD.getRange().clone()\n",
    "scaleOpD.forward(False, vecD, vecD1)\n",
    "print(\"Norm of the input = %s\" % vecD.norm())\n",
    "print(\"Norm of the output = %s\" % vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine an operator that spreads and collects a local vector onto a Dask-vector chunks. Such operator is useful when the same vector is employed multiple times on different operators embarrassingly-parallelizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.2735610008239746 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.061138153076171875 seconds\n",
      "Dot products add=False: domain=1.127771e+02 range=1.127771e+02 \n",
      "Absolute error: 4.263256e-14\n",
      "Relative error: 3.780251e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.2522130012512207 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.07279467582702637 seconds\n",
      "Dot products add=True: domain=2.255542e+02 range=2.255542e+02 \n",
      "Absolute error: 8.526513e-14\n",
      "Relative error: 3.780251e-16 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "S = o.DaskSpread(client, vec, chunks)\n",
    "S.dotTest(True) # checking dot-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.36614108085632324 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.18489599227905273 seconds\n",
      "Dot products add=False: domain=7.069724e+01 range=7.069724e+01 \n",
      "Absolute error: 1.165290e-12\n",
      "Relative error: 1.648282e-14 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.4546501636505127 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.1888599395751953 seconds\n",
      "Dot products add=True: domain=1.413945e+02 range=1.413945e+02 \n",
      "Absolute error: 2.330580e-12\n",
      "Relative error: 1.648282e-14 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ettorebiondi/PycharmProjects/OccamyPy/occamypy/numpy/vector.py:74: RuntimeWarning: overflow encountered in square\n",
      "  rms = np.sqrt(np.mean(np.square(self.getNdArray())))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First element of x = -0.6255070644304621\n",
      "First element of y = -6.255070644304621\n"
     ]
    }
   ],
   "source": [
    "#Chain of scaling and spreading operator\n",
    "scale_S = scaleOpD * S\n",
    "scale_S.dotTest(True) # checking dot-product\n",
    "# Testing product of Dask Operators\n",
    "x = vec.rand()\n",
    "y = scale_S.getRange().clone()\n",
    "scale_S.forward(False, x, y)\n",
    "print(\"\\nFirst element of x = %s\" % x.getNdArray()[0,0])\n",
    "print(\"First element of y = %s\" % y.getNdArray()[0][0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask blocky operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we worked with block-diagonal operators. Let's try now to work with blocky operators defined as follows:\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{A}_{blocky} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{A}_{11} & \\mathbf{A}_{12} \\\\\n",
    "\\mathbf{A}_{21} & \\mathbf{A}_{22}\n",
    "\\end{bmatrix},\n",
    "\\end{eqnarray}\n",
    "where $\\mathbf{A}_{ij}$ defines each opearator composing $\\mathbf{A}_{blocky}$. In here, each worked will take care of each row of this operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use only two workers\n",
    "n1 = 3\n",
    "n2 = 2\n",
    "vec1 = o.VectorNumpy((n1, 1))\n",
    "vec2 = o.VectorNumpy((n2, 1))\n",
    "# We use the parameter chunks to select which worker will have a given vector instance\n",
    "chunks = (1, 0, 0, 1)\n",
    "vecD = o.DaskVector(client, vectors=[vec1, vec2], chunks=chunks).zero()\n",
    "# Now create the list of arguments in a column-wise fashion\n",
    "A11 = np.random.rand(n1, n1)\n",
    "A12 = np.random.rand(n1, n2)\n",
    "A21 = np.random.rand(n2, n1)\n",
    "A22 = np.random.rand(n2, n2)\n",
    "A_args = [(A11, vec1, vec1), (A21, vec1, vec2), (A12, vec2, vec1), (A22, vec2, vec2)]\n",
    "# Instantiating Dask operator\n",
    "A_blocky = o.DaskOperator(client, o.Matrix, A_args, chunks, op_kind=\"blocky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to apply the forward operator and compare the result by applying the $\\mathbf{A}_{blocky}$ matrix locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error |y_loc-y_dask|_2 = 1.7554167342883506e-16\n"
     ]
    }
   ],
   "source": [
    "# Dask blocky operator\n",
    "x = vecD.rand()\n",
    "y = vecD.clone()\n",
    "A_blocky.forward(False, x, y)\n",
    "# Local operations\n",
    "A_mat = np.block([[A11, A12], [A21, A22]])\n",
    "x_loc = np.concatenate(x.getNdArray(), axis=0)\n",
    "y_loc = np.matmul(A_mat, x_loc)\n",
    "error = y_loc - np.concatenate(y.getNdArray(), axis=0)\n",
    "print(\"Error |y_loc-y_dask|_2 = %s\" % np.linalg.norm(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to the adjoint operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error |x_loc-x_dask|_2 = 1.6653345369377348e-16\n"
     ]
    }
   ],
   "source": [
    "# Dask blocky operator\n",
    "y.rand()\n",
    "A_blocky.adjoint(False, x, y)\n",
    "# Local operations\n",
    "# A_mat = np.block([[A11, A12], [A21, A22]])\n",
    "y_loc = np.concatenate(y.getNdArray(), axis=0)\n",
    "x_loc = np.matmul(A_mat.T, y_loc)\n",
    "error = x_loc - np.concatenate(x.getNdArray(), axis=0)\n",
    "print(\"Error |x_loc-x_dask|_2 = %s\" % np.linalg.norm(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test the dot-product test of the blocky operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.05706906318664551 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.03998994827270508 seconds\n",
      "Dot products add=False: domain=5.652114e-01 range=5.652114e-01 \n",
      "Absolute error: 1.110223e-16\n",
      "Relative error: 1.964262e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.05144476890563965 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.044786930084228516 seconds\n",
      "Dot products add=True: domain=1.130423e+00 range=1.130423e+00 \n",
      "Absolute error: 0.000000e+00\n",
      "Relative error: 0.000000e+00 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "A_blocky.dotTest(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}