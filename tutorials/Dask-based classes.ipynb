{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple usage of Dask vectors and Dask operators\n",
    "\n",
    "@Author: Ettore Biondi - ebiondi@caltech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we describe the usage of the Dask-based classes. These objects are designed to take advantage of computational power of computer clusters composed of multiple nodes. To this end, we employ the existing classes in combination of Dask (https://dask.org/). We show the syntax with which a user can instantiate Dask-based objects from existing constructors using a local Dask cluster. The same syntax applies to the other supported Dask clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! DATAPATH not found. The folder /tmp will be used to write binary files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/fpicetti/miniconda3/envs/occd/lib/python3.10/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import occamypy as o\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import rcParams\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams.update({\n",
    "    'image.cmap'     : 'gray',\n",
    "    'image.aspect'   : 'auto',\n",
    "    'image.interpolation': None,\n",
    "    'axes.grid'      : False,\n",
    "    'figure.figsize' : (10, 6),\n",
    "    'savefig.dpi'    : 300,\n",
    "    'axes.labelsize' : 14,\n",
    "    'axes.titlesize' : 16,\n",
    "    'font.size'      : 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'text.usetex'    : True,\n",
    "    'font.family'    : 'serif',\n",
    "    'font.serif'     : 'Latin Modern Roman',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting a Dask cluster and client\n",
    "Let's start by starting a local Dask client and show how to get some information from such object. We are going to start 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DaskClient in module occamypy.dask.utils:\n",
      "\n",
      "class DaskClient(builtins.object)\n",
      " |  DaskClient(**kwargs)\n",
      " |  \n",
      " |  Dask Client to be used with Dask vectors and operators\n",
      " |  \n",
      " |  Notes:\n",
      " |      The Kubernetes pods are created using the Docker image \"ettore88/occamypy:devel\".\n",
      " |      To change the image to be use, provide the item image within the kube_params dictionary.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      DaskClient constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          1) Cluster with shared file system and ssh capability\n",
      " |      \n",
      " |              hostnames (list) [None]: host names or IP addresses of the machines that the user wants to use in their cluster/client (First hostname will be running the scheduler!)\n",
      " |              scheduler_file_prefix (str): prefix to used to create dask scheduler-file.\n",
      " |              logging (bool) [True]: whether to log scheduler and worker stdout to files within dask_logs folder\n",
      " |                  Must be a mounted path on all the machines. Necessary if hostnames are provided [$HOME/scheduler-]\n",
      " |      \n",
      " |          2) Local cluster\n",
      " |              local_params (dict) [None]: Local Cluster options (see help(LocalCluster) for help)\n",
      " |              n_wrks (int) [1]: number of workers to start\n",
      " |      \n",
      " |          3) PBS cluster\n",
      " |              pbs_params (dict) [None]: PBS Cluster options (see help(PBSCluster) for help)\n",
      " |              n_jobs (int): number of jobs to be submitted to the cluster\n",
      " |              n_wrks (int) [1]: number of workers per job\n",
      " |      \n",
      " |          4) LSF cluster\n",
      " |              lfs_params (dict) [None]: LSF Cluster options (see help(LSFCluster) for help)\n",
      " |              n_jobs (int): number of jobs to be submitted to the cluster\n",
      " |              n_wrks (int) [1]: number of workers per job\n",
      " |      \n",
      " |          5) SLURM cluster\n",
      " |              slurm_params (dict) [None]: SLURM Cluster options (see help(SLURMCluster) for help)\n",
      " |              n_jobs (int): number of jobs to be submitted to the cluster\n",
      " |              n_wrks (int) [1]: number of workers per job\n",
      " |      \n",
      " |          6) Kubernetes cluster\n",
      " |              kube_params (dict): KubeCluster options\n",
      " |               (see help(KubeCluster) and help(make_pod_spec) for help) [None]\n",
      " |              n_wrks (int) [1]: number of workers per job\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(o.DaskClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 01:49:36,427 - distributed.diskutils - INFO - Found stale lock file and directory '/nas/home/fpicetti/occamypy/tutorials/dask-worker-space/worker-2l1fb0kd', purging\n",
      "2022-04-22 01:49:36,430 - distributed.diskutils - INFO - Found stale lock file and directory '/nas/home/fpicetti/occamypy/tutorials/dask-worker-space/worker-am8u1jzt', purging\n",
      "2022-04-22 01:49:36,433 - distributed.diskutils - INFO - Found stale lock file and directory '/nas/home/fpicetti/occamypy/tutorials/dask-worker-space/worker-ncn2vuoy', purging\n"
     ]
    }
   ],
   "source": [
    "client_params = {\"processes\":True}\n",
    "client = o.DaskClient(local_params=client_params, n_wrks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers number = 4\n",
      "Workers Ids = ['tcp://127.0.0.1:34903', 'tcp://127.0.0.1:37813', 'tcp://127.0.0.1:45375', 'tcp://127.0.0.1:46463']\n",
      "Dashboard link (requires bokeh>=2.1.1): http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "print(\"Workers number = %d\" % client.num_workers)\n",
    "print(\"Workers Ids = %s\" % client.WorkerIds)\n",
    "print(\"Dashboard link (requires bokeh>=2.1.1): %s\" % client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask vectors\n",
    "Now that we have a Dask client, we can instantiate vectors using the Dask interface. The currently supported methods to create such objects are the following:\n",
    "1. Instantiate a vector template and spread it using the chunk parameter\n",
    "2. Instantiate multiple vectors and spreading them to the given workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/fpicetti/miniconda3/envs/occd/lib/python3.10/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n",
      "/nas/home/fpicetti/miniconda3/envs/occd/lib/python3.10/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n",
      "/nas/home/fpicetti/miniconda3/envs/occd/lib/python3.10/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n",
      "/nas/home/fpicetti/miniconda3/envs/occd/lib/python3.10/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "# Method 1\n",
    "vec_temp = o.VectorNumpy((200, 300))\n",
    "chunks = (3, 4, 6, 2)  # 3 vectors to worker 1; 4 vectors to worker 2; ...\n",
    "vecD = o.DaskVector(client, vector_template=vec_temp, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vecD inherits all the methods from the abstract vector class. Let's try some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300), (200, 300)]\n",
      "Dask vector norm = 548.2163880651233\n",
      "Scaled Dask vector norm = 5482.163880651233\n",
      "Sum Dask vector norm = 10964.327761302466\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\" % vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\" % vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\" % vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1 + vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\" % vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dask vector contains a list of the future objects pointing to the vector chunks. Let's see how to see which worker has a given chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future object to first chunk: <Future: finished, type: occamypy.numpy.vector.VectorNumpy, key: _call_clone-59549477-c813-405f-92d3-93abf243b457>\n",
      "Worker having given chunk: {'_call_clone-59549477-c813-405f-92d3-93abf243b457': ('tcp://127.0.0.1:34903',)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Future object to first chunk: %s\" % vecD.vecDask[0])\n",
    "print(\"Worker having given chunk: %s\" % client.client.who_has(vecD.vecDask[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a vector using a different Dask-vector constructor. Here, we instantiate all the chunks and then spread them onto the given workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = o.VectorNumpy((200, 300))\n",
    "vec2 = o.VectorNumpy((10, 30))\n",
    "vec3 = o.VectorNumpy((250, 1))\n",
    "\n",
    "# We use the parameter chunks to select which worker will have a given vector instance\n",
    "vecD = o.DaskVector(client, vectors=[vec1, vec2, vec3], chunks=(1, 1, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try similar tests as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(200, 300), (10, 30), (250, 1)]\n",
      "Dask vector norm = 141.93710738443562\n",
      "Scaled Dask vector norm = 1419.3710738443563\n",
      "Sum Dask vector norm = 2838.7421476887125\n",
      "\n",
      "Future object to third chunk: <Future: finished, type: occamypy.numpy.vector.VectorNumpy, key: VectorNumpy-4d98d84ba98eef7fefe8df41ad58452f>\n",
      "Worker having given chunk: {'VectorNumpy-4d98d84ba98eef7fefe8df41ad58452f': ('tcp://127.0.0.1:46463',)}\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\" % vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\" % vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\" % vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1 + vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\" % vecD1.norm())\n",
    "print(\"\\nFuture object to third chunk: %s\" % vecD.vecDask[2])\n",
    "print(\"Worker having given chunk: %s\" % client.client.who_has(vecD.vecDask[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask operators\n",
    "Now, let's try to instantiate Dask operators. These kind of objects are pretty useful when large-scale problems have to be solved. The main idea behind the interface is to pass a given operator constructor and the necessary parameters so that the object is directly instantiated within the Dask workers of a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simple scaling operator acting on each chunk of a Dask Vector\n",
    "vec = o.VectorNumpy((100, 25))\n",
    "chunks = (2, 3, 5, 10)\n",
    "sc = 10.0\n",
    "vecD = o.DaskVector(client, vector_template=vec, chunks=chunks)\n",
    "# Creating list of lists of the arguments for the operator's constructor\n",
    "scal_op_args = [(vec_i, sc) for vec_i in vecD.vecDask]\n",
    "\n",
    "# Instantiating Dask operator\n",
    "scaleOpD = o.DaskOperator(client, o.Scaling, scal_op_args, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the Dask vector class, a Dask operator object inherits all the methods from the corresponding abstract class. Let's try some of those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.058522939682006836 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.0875239372253418 seconds\n",
      "Dot products add=False: domain=2.051316e+02 range=2.051316e+02 \n",
      "Absolute error: 2.273737e-13\n",
      "Relative error: 1.108428e-15 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.09615087509155273 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.08543872833251953 seconds\n",
      "Dot products add=True: domain=4.102633e+02 range=4.102633e+02 \n",
      "Absolute error: 1.136868e-13\n",
      "Relative error: 2.771070e-16 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Maximum eigenvalue = 10.000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Dot-product test\n",
    "scaleOpD.dotTest(True)\n",
    "# Power method\n",
    "max_eig = scaleOpD.powerMethod()\n",
    "print(\"\\nMaximum eigenvalue = %s\" % max_eig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to apply this Dask operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the input = 129.61869508090254\n",
      "Norm of the output = 1296.1869508090251\n"
     ]
    }
   ],
   "source": [
    "vecD.rand()\n",
    "vecD1 = scaleOpD.getRange().clone()\n",
    "scaleOpD.forward(False, vecD, vecD1)\n",
    "print(\"Norm of the input = %s\" % vecD.norm())\n",
    "print(\"Norm of the output = %s\" % vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine an operator that spreads and collects a local vector onto a Dask-vector chunks. Such operator is useful when the same vector is employed multiple times on different operators embarrassingly-parallelizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.37352514266967773 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.3142249584197998 seconds\n",
      "Dot products add=False: domain=8.811984e+01 range=8.811984e+01 \n",
      "Absolute error: 5.684342e-14\n",
      "Relative error: 6.450694e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.3676631450653076 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.32789039611816406 seconds\n",
      "Dot products add=True: domain=1.762397e+02 range=1.762397e+02 \n",
      "Absolute error: 1.705303e-13\n",
      "Relative error: 9.676042e-16 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "S = o.DaskSpread(client, vec, chunks)\n",
    "S.dotTest(True) # checking dot-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.47357606887817383 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.5163707733154297 seconds\n",
      "Dot products add=False: domain=8.315102e+01 range=8.315102e+01 \n",
      "Absolute error: 1.847411e-13\n",
      "Relative error: 2.221754e-15 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.5049726963043213 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.44762420654296875 seconds\n",
      "Dot products add=True: domain=1.663020e+02 range=1.663020e+02 \n",
      "Absolute error: 5.684342e-14\n",
      "Relative error: 3.418083e-16 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "First element of x = -0.19444195935371655\n",
      "First element of y = -1.9444195935371655\n"
     ]
    }
   ],
   "source": [
    "#Chain of scaling and spreading operator\n",
    "scale_S = scaleOpD * S\n",
    "scale_S.dotTest(True) # checking dot-product\n",
    "# Testing product of Dask Operators\n",
    "x = vec.rand()\n",
    "y = scale_S.getRange().clone()\n",
    "scale_S.forward(False, x, y)\n",
    "print(\"\\nFirst element of x = %s\" % x.getNdArray()[0,0])\n",
    "print(\"First element of y = %s\" % y.getNdArray()[0][0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask blocky operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we worked with block-diagonal operators. Let's try now to work with blocky operators defined as follows:\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{A}_{blocky} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{A}_{11} & \\mathbf{A}_{12} \\\\\n",
    "\\mathbf{A}_{21} & \\mathbf{A}_{22}\n",
    "\\end{bmatrix},\n",
    "\\end{eqnarray}\n",
    "where $\\mathbf{A}_{ij}$ defines each opearator composing $\\mathbf{A}_{blocky}$. In here, each worked will take care of each row of this operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use only two workers\n",
    "n1 = 3\n",
    "n2 = 2\n",
    "vec1 = o.VectorNumpy((n1, 1))\n",
    "vec2 = o.VectorNumpy((n2, 1))\n",
    "\n",
    "# We use the parameter chunks to select which worker will have a given vector instance\n",
    "chunks = (1, 0, 0, 1)\n",
    "vecD = o.DaskVector(client, vectors=[vec1, vec2], chunks=chunks).zero()\n",
    "\n",
    "# Now create the list of arguments in a column-wise fashion\n",
    "A11 = o.VectorNumpy((n1, n1)).rand()\n",
    "A12 = o.VectorNumpy((n1, n2)).rand()\n",
    "A21 = o.VectorNumpy((n2, n1)).rand()\n",
    "A22 = o.VectorNumpy((n2, n2)).rand()\n",
    "\n",
    "A_args = [(A11, vec1, vec1), (A21, vec1, vec2), (A12, vec2, vec1), (A22, vec2, vec2)]\n",
    "\n",
    "# Instantiating Dask operator\n",
    "A_blocky = o.DaskOperator(client, o.Matrix, A_args, chunks, op_kind=\"blocky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to apply the forward operator and compare the result by applying the $\\mathbf{A}_{blocky}$ matrix locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error |y_loc-y_dask|_2 = 1.0007415106216802e-16\n"
     ]
    }
   ],
   "source": [
    "# Dask blocky operator\n",
    "x = vecD.rand()\n",
    "y = A_blocky * x\n",
    "\n",
    "# Local operations\n",
    "A_mat = np.block([[A11.getNdArray(), A12.getNdArray()],\n",
    "                  [A21.getNdArray(), A22.getNdArray()]])\n",
    "\n",
    "x_loc = np.concatenate(x.getNdArray(), axis=0)\n",
    "\n",
    "y_loc = np.matmul(A_mat, x_loc)\n",
    "\n",
    "error = y_loc - np.concatenate(y.getNdArray(), axis=0)\n",
    "\n",
    "print(\"Error |y_loc-y_dask|_2 = %s\" % np.linalg.norm(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to the adjoint operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error |x_loc-x_dask|_2 = 6.206335383118183e-17\n"
     ]
    }
   ],
   "source": [
    "# Dask blocky operator\n",
    "y.rand()\n",
    "A_blocky.adjoint(False, x, y)\n",
    "\n",
    "# Local operations\n",
    "y_loc = np.concatenate(y.getNdArray(), axis=0)\n",
    "x_loc = np.matmul(A_mat.T, y_loc)\n",
    "\n",
    "error = x_loc - np.concatenate(x.getNdArray(), axis=0)\n",
    "\n",
    "print(\"Error |x_loc-x_dask|_2 = %s\" % np.linalg.norm(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test the dot-product test of the blocky operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.04236960411071777 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.04285073280334473 seconds\n",
      "Dot products add=False: domain=3.596495e-01 range=3.596495e-01 \n",
      "Absolute error: 1.665335e-16\n",
      "Relative error: 4.630438e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.07330083847045898 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.0720217227935791 seconds\n",
      "Dot products add=True: domain=7.192990e-01 range=7.192990e-01 \n",
      "Absolute error: 3.330669e-16\n",
      "Relative error: 4.630438e-16 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "A_blocky.dotTest(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
