{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of Dask vectors and Dask operators on a Kubernetes cluster\n",
    "\n",
    "@Author: Ettore Biondi - ebiondi@caltech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to start a Dask client using an existing Kubernetes cluster and run any method present within any Dask-based class. The interface we use is based on the Dask Kubernetes one (https://kubernetes.dask.org/en/latest/). This process's power is given by the fact that the same syntax as the local cluster is used to run similar operations. However, all the computations are performed within the remote Kubernetes cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! DATAPATH not found. The folder /tmp will be used to write binary files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import occamypy\n",
    "#Plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# %matplotlib inline\n",
    "params = {\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray',\n",
    "    'savefig.dpi': 300,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 14, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 14,\n",
    "    'font.size': 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'text.usetex':True\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, make sure you have a running Kubernetes cluster. In our case, we are using a Kubernetes cluster created employing the Google Cloud Platform (GCP). Any other Cloud provider can be used to use the Dask Kubernetes interface since it based on Kubernetes native commands. First, let's check how many nodes in the cluster are available by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                    STATUS   ROLES    AGE   VERSION\r\n",
      "gke-test-cluster-pool-1-c7981ec8-3mst   Ready    <none>   98m   v1.16.13-gke.401\r\n",
      "gke-test-cluster-pool-1-c7981ec8-s42f   Ready    <none>   98m   v1.16.13-gke.401\r\n",
      "gke-test-cluster-pool-1-c7981ec8-tnks   Ready    <none>   98m   v1.16.13-gke.401\r\n",
      "gke-test-cluster-pool-1-c7981ec8-xxdd   Ready    <none>   98m   v1.16.13-gke.401\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we see that we have 4 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now instantiate the Dask client object using the occamypy interface. For more information run \"help(occamypy.DaskClient)\". Currently, we employ kubefwd (https://github.com/txn2/kubefwd) to allow communication between the local machine and the Kubernetes cluster. Therefore, one needs to run in the background the following command:\n",
    "\n",
    "```sudo kubefwd svc -n default -n kube-system ```\n",
    "\n",
    "which requires root access. We are currently working on finding a solution to this limitation. Once, this command is running in the background, it is possible to start the Dask-Kubernetes cluster and client. The following command will take a few moment to start since a container for the scheduler and each worker needs to be created.\n",
    "The user can check this process by running the following kubectl command:\n",
    "\n",
    "```kubectl get pods```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating scheduler pod on cluster. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "client_params = {\"memory_limit\":'1G', \"memory_request\":'1G',\"cpu_limit\":1, \"cpu_request\":1}\n",
    "client = occamypy.DaskClient(kube_params=client_params, n_wrks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as in the [Dask-based classes](./Dask-based&#32;classes.ipynb) tutorial, let's check the number of workers and run some simple computation using the Dask-Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers = 3\n",
      "Workers Ids = ['tcp://10.68.0.8:44173', 'tcp://10.68.1.8:33953', 'tcp://10.68.2.10:45987']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of workers = %d\"%client.getNworkers())\n",
    "print(\"Workers Ids = %s\"%client.getWorkerIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask vectors\n",
    "The same exact syntax can be used to perform vector operations as in the other examples. However, all the computations are performed on the Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_temp = occamypy.VectorNumpy((200, 340))\n",
    "chunks = (5, 3, 6) # 5 vectors to worker 1; 3 vectors to worker 2; ...\n",
    "vecD = occamypy.DaskVector(client, vector_template=vec_temp, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check some of the vector chunks' properties and vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200), (340, 200)]\n",
      "Dask vector norm = 563.6544056088085\n",
      "Scaled Dask vector norm = 5636.544056088079\n",
      "Sum Dask vector norm = 11273.088112176158\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\" % vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\" % vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\" % vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1 + vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\" % vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask operators\n",
    "Let's now try the Dask operators using the Kubernetes cluster. We are going to test the same operations as in the other Dask interface tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simple scaling operator acting on each chunk of a Dask Vector\n",
    "vec = occamypy.VectorNumpy((100, 25))\n",
    "chunks = (20, 5, 12)\n",
    "sc = 10.0\n",
    "vecD = occamypy.DaskVector(client, vector_template=vec, chunks=chunks)\n",
    "# Creating list of lists of the arguments for the operator's constructor\n",
    "scal_op_args = [(vec_i, sc) for vec_i in vecD.vecDask]\n",
    "\n",
    "# Instantiating Dask operator\n",
    "scaleOpD = occamypy.DaskOperator(client, occamypy.Scaling, scal_op_args, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.4625699520111084 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.44726991653442383 seconds\n",
      "Dot products add=False: domain=2.758842e+03 range=2.758842e+03 \n",
      "Absolute error: 2.273737e-12\n",
      "Relative error: 8.241636e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.47759199142456055 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.4708428382873535 seconds\n",
      "Dot products add=True: domain=5.517683e+03 range=5.517683e+03 \n",
      "Absolute error: 2.728484e-12\n",
      "Relative error: 4.944981e-16 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Maximum eigenvalue = 9.999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Dot-product test\n",
    "scaleOpD.dotTest(True)\n",
    "# Power method\n",
    "max_eig = scaleOpD.powerMethod()\n",
    "print(\"\\nMaximum eigenvalue = %s\" % max_eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the input = 175.27081379444783\n",
      "Norm of the output = 1752.7081379444776\n"
     ]
    }
   ],
   "source": [
    "vecD.rand()\n",
    "vecD1 = scaleOpD.getRange().clone()\n",
    "scaleOpD.forward(False, vecD, vecD1)\n",
    "print(\"Norm of the input = %s\" % vecD.norm())\n",
    "print(\"Norm of the output = %s\" % vecD1.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 4.349317789077759 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.6235499382019043 seconds\n",
      "Dot products add=False: domain=8.813910e+01 range=8.813910e+01 \n",
      "Absolute error: 4.263256e-14\n",
      "Relative error: 4.836964e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 3.8977253437042236 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.43741893768310547 seconds\n",
      "Dot products add=True: domain=1.762782e+02 range=1.762782e+02 \n",
      "Absolute error: 2.842171e-14\n",
      "Relative error: 1.612321e-16 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "S = occamypy.DaskSpread(client, vec, chunks)\n",
    "S.dotTest(True) # checking dot-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 4.366874933242798 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 1.1945748329162598 seconds\n",
      "Dot products add=False: domain=1.974351e+03 range=1.974351e+03 \n",
      "Absolute error: 1.818989e-12\n",
      "Relative error: 9.213098e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 4.2433929443359375 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 1.0472321510314941 seconds\n",
      "Dot products add=True: domain=3.948703e+03 range=3.948703e+03 \n",
      "Absolute error: 2.728484e-12\n",
      "Relative error: 6.909824e-16 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "First element of x = 0.6018041355008692\n",
      "First element of y = 6.018041355008692\n"
     ]
    }
   ],
   "source": [
    "#Chain of scaling and spreading operator\n",
    "scale_S = scaleOpD * S\n",
    "scale_S.dotTest(True) # checking dot-product\n",
    "# Testing product of Dask Operators\n",
    "x = vec.rand()\n",
    "y = scale_S.getRange().clone()\n",
    "scale_S.forward(False, x, y)\n",
    "print(\"\\nFirst element of x = %s\" % x.getNdArray()[0,0])\n",
    "print(\"First element of y = %s\" % y.getNdArray()[0][0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
